ğŸ”¢ Parameter Count
GPT-4: Approximately 1.8 trillion parameters, structured as 8 models with 220 billion parameters each. â€‹
DeepSeek-R1: Total of 671 billion parameters; utilizes a Mixture of Experts (MoE) architecture with 37 billion parameters activated per inference. â€‹

ğŸ’¾ Model Size (Use Qunatization to reduce the size)
GPT-4: Estimated to require over 800 GB of storage, depending on precision and architecture.â€‹
DeepSeek-R1: Approximately 404 GB in 4-bit quantized form.



Coqui's XTTS-v2 model supports 17 languages, including Hindi and English. However, Tamil and Telugu are not currently among the supported languages . For Tamil and Telugu, alternative open-source TTS solutions like OpenTTS, which integrates various TTS systems, might be explored

Add a mixture of 20% background noise of call center once custom voice is prepared.

âœ… What You'll Need to Train a Custom Voice
1. Recording Dataset (Your voice)
30 to 60 minutes of clear, high-quality speech

In any single language (preferably English or Hindi â€” but Coqui adapts!)
No background noise, no echo (record in a quiet room)

You can:
Read sentences from LibriTTS
Use scripts like subtitles, audiobooks, or news articles

Save each sentence as:
my_voice_001.wav
my_voice_002.wav
and so on...

Create a matching .csv file like:
vbnet
wav_path|text
my_voice_001.wav|Hello, my name is Dushyant.
my_voice_002.wav|I work on AI and love building voice agents.
...

2. Language Flexibility
You only need to record in one language (e.g. English), and the model will learn your voice timbre, not language.

âœ… After training, you can synthesize:
tts_model.tts("à¤®à¥ˆà¤‚ à¤­à¥à¤—à¤¤à¤¾à¤¨ à¤¨à¤¹à¥€à¤‚ à¤•à¤° à¤¸à¤•à¤¤à¤¾", speaker_wav="my_voice.wav", language="hi")
and it will speak Hindi in your voice. ğŸ¤¯

âœ… Coqui TTS Training Workflow (Custom Voice)
ğŸ“¦ Setup
git clone https://github.com/coqui-ai/TTS
cd TTS
pip install -r requirements.txt
ğŸ“ Prepare Your Data
Structure your folder like:

markdown

datasets/
â””â”€â”€ my_voice_dataset/
    â”œâ”€â”€ wavs/
    â”‚   â”œâ”€â”€ my_voice_001.wav
    â”‚   â””â”€â”€ ...
    â””â”€â”€ metadata.csv
âš™ï¸ Create a config
Use the your_tts config as a starting point.

Update:
yaml
output_path: ./output/
datasets:
  - name: my_voice_dataset
    path: ./datasets/my_voice_dataset
    meta_file_train: metadata.csv
    meta_file_val: metadata.csv
ğŸš€ Train the model

python TTS/bin/train.py --config_path config.yaml
This will take ~2â€“5 hours on GPU (can also run on Colab). You'll get a best_model.pth.

âœ… How to Use Your Voice to Speak Any Language
After training, load the model in your app:

from TTS.api import TTS

tts_model = TTS(model_path="output/best_model.pth", config_path="output/config.json")
tts_model.tts_to_file(text="Hola, Â¿cÃ³mo estÃ¡s?", language="es", speaker_wav="my_voice_001.wav", file_path="es.wav")

ğŸ‰ The output will be:
Spanish words in your cloned voice!

ğŸ” Recap
Step	Detail
ğŸ—£ï¸ Record	30â€“60 mins of your voice (any language)
ğŸ—‚ï¸ Format	WAV + metadata.csv
ğŸ§  Train	Use your_tts config in Coqui
ğŸŒ Use	Speak in Hindi, Marathi, Tamil, English, Spanish... all in your voice





âœ… Result
Feature	          gTTS	       Coqui TTS
Multilingual	   âŒ Limited	   âœ… 100+
Offline	         âŒ No	         âœ… Yes
Custom voice	   âŒ No	         âœ… Yes
Natural voice	   âš ï¸ Robotic	    âœ… More human-like
Speed	           âœ… Fast	       âš ï¸ Slower but high-quality